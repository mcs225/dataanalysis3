[
["index.html", "Data Analysis in Social Science 3 1 Introduction 1.1 Things to do before the next class", " Data Analysis in Social Science 3 Alexey Bessudnov 2018-02-19 1 Introduction This is a website for the Data Analysis in Social Science 3 module at the University of Exeter (SOC2094/3094 POL2094/3094) as offered in Term 2 in 2018. The website will be updated with new R Markdown scripts as the course progresses. All the scripts are provided on the ‘as is’ basis. The idea for this module is to teach you how to work with complex longitudinal data sets using data from the Understanding Society, a longitudinal household survey conducted in the UK. You will learn how to read complex data into R, manipulate and summarise data using dplyr, merge and restructure data frames, visualise data using ggplot2, create statistical reports with R Markdown and (possibly) interactive applications with Shiny. For more details see the module outline. The module is organised according to the “flipped classroom” pedagogy. This means that you read new material and do exercises before the class, and in class we work together on the exercises and discuss how what you learned at home can be applied to the Understanding Society data. The readings and exercises mostly come from the R for Data Science book by G.Grolemund and H.Wickham. The pre-requisites for this module are SOC/POL1041 and SOC/POL2077. All the scripts and other materials are available in the Github repository for the module: https://github.com/abessudnov/dataanalysis3 1.1 Things to do before the next class Before coming to class 2 please do the following: Register an account with the UK Data Service, create a data usage (or join the existing data usage that I have created) and download the Understanding Society data in the tab delimited format (SN6614). Read the User Manual and familiarise yourself with the structure of the data. Install Git and register an account on Github (if you do not have it already). Then you can either create a new repository for this module or fork my repository (see the link above). Create a project in R Studio for this repository. To learn how Git and Github work take this free online course: https://www.datacamp.com/courses/introduction-to-git-for-data-science/ In the root folder for your project create a folder “data” and put there the Understanding Society data as you downloaded them. The next subfolder must be “UKDA-6614-tab”. Never change anything in this folder. Also create an empty “myData” folder in the root folder. You do not want to track these two folders on Github. To avoid this, include the following two lines in your .gitignore file: data/ myData/ Read ch.11 (Data Import) from R for Data Science and do the exercises - http://r4ds.had.co.nz/data-import.html "],
["module-outline.html", "2 Module outline 2.1 Practical arrangements 2.2 Aims of the module 2.3 Attendance 2.4 Assessment 2.5 Syllabus plan 2.6 Reading list", " 2 Module outline 2.1 Practical arrangements Classes: Monday, 11.30am - 1.30pm, WSL 220 Classes begin on 15 January and end on 26 March. The class on 22 January (week 2) has been cancelled and moved to Friday 2 February, 10.30 - 12.30, WSL 220. Office hours (Amory A341) Monday, 2-3pm Friday, 12-1pm Email: A.Bessudnov [at] exeter.ac.uk 2.2 Aims of the module This is a fourth module in the data analysis in the social sciences series. In the Introduction to Social Data you learned the basics of descriptive statistics and R. Data Analysis 1 introduced you to statistical inference. Data Analysis 2 covered linear regression analysis. In Data Analysis 3 we are not going to learn new statistical techniques, but will focus on how to apply the techniques you already know to the analysis of real-life data sets and how to produce statistical reports. This is a skill that you may need in a variety of jobs where data analytic expertise is required, such as marketing analysis, policy analysis in various fields, web analytics, data journalism, academic research, etc. You already know how to use R to describe data and run simple statistical models. However, real-life data rarely come in the form of a perfectly formatted csv file ready for the analysis. The real life data sets often need to be reshaped, merged, recoded, aggregated and modified in various ways before you can even start your analysis. Unless you know how to do this you will not be able to produce good statistical reports. This year in this module we will use data from the Understanding Society, a large household panel study conducted in the UK. In the Immigration module we already used the cross-sectional Understanding Society data. In this module we will work with the longitudinal data, which introduces a number of technical challenges. Throughout the module we will use R for statistical analysis. You are expected to know the basics of data analysis in R. The only way to learn data analysis is to do data analysis. I will not be able to teach you this, but I can guide your independent learning. This year we will try the “flipped classroom” model of teaching. This means that you will be expected to read and master the required material BEFORE the class and we will use the time in class to answer additional questions and check your solutions rather than introduce new material. The pre-requisites for this module are POL/SOC1041 and POL/SOC2077. 2.3 Attendance This module is quite technical. As with other technical skills, missing some initial bits means that you may not be able to catch up. Attendance in this module is crucial. If you do not attend you will not be able to do well in this module. Even skipping a couple of classes will have negative consequences for your understanding of the material. Another negative consequence will be that you will slow the rest of the class down as I will have to explain the same things several times. If you plan not to attend classes please do not take this optional module. 2.4 Assessment The assessment for this module is a report of 3,500 words (in addition to figures and tables) with the results of statistical analysis you will undertake. This will be 100% of your final mark for this module. You will be given questions for the reports later in the module. In your analysis you will use the Understanding Society data. The deadline for submitting your reports through eBart is 29 March at 2pm. You will receive your marks and feedback by 5 May. Late submissions up to two weeks after the deadline will be capped at 40%. Submissions that are late for more than two weeks will not be accepted. 2.5 Syllabus plan I may change some topics as we proceed. Data structures in R Manipulating data with dplyr Longitudinal data in R. Wide and long formats. Reshaping Data visualisation with ggplot2 Producing statistical reports with R Markdown Interactive applications with Shiny Loops and other control structures. The apply family of functions Writing functions in R 2.6 Reading list The main text for this module: G.Grolemund &amp; H.Wickham. (2016). R for Data Science. Freely available at http://r4ds.had.co.nz/ In addition to this you can the following sources (among many others books on R). H.Wickham. (2015). ggplot2. Elegant Graphics for Data Analysis. 2nd ed. Springer. W.Chang. (2013). R Graphics Cookbook. O’Reilly. P.Spector. (2008). Data Manipulation with R. Springer. N.Matloff. (2011). The Art of R Programming. No Starch Press. H.Wickham. (2014). Advanced R. Chapman &amp; Hall. "],
["assignment.html", "3 Assignment", " 3 Assignment Your assignment for this module is to choose a topic, conduct an independent statistical analysis with the Understanding Society data and write up your results in a report that is about 3,500 words long. I wanted to give you as much flexibility as possible in preparing the report. I will not provide a detailed guidance on what you should analyse and how you should this. As this is an advanced module I expect you to be able to formulate a research question, identify the data you need and conduct the analysis independently. In other words, the idea is to throw you into the sea of data and find out if you can come up with a nice statistical report that answers a well defined question. However, there are a few rules. You must use the Understanding Society data and I suggest you use data from the indresp files (these are individual adult questionnaires). You must use longitudinal data, i.e. data from more than one wave and preferrably all seven waves of the Understanding Society. This will depend on your question though. If you only have data at two time points available and produce good analysis this is totally fine. But if you have data in all seven waves and only use two this is not fine. Generally you would select one time-varying variable and explore changes over time, in the whole sample and different population subgroups. For example, you may explore how people’s incomes changed from 2008 to 2016. You may want to conduct your analysis by gender, age group, location, etc. Other possible variables: Health Employment and job mobility State benefits Any other topic that you find interesting and that has longitudinal data available in the Understanding Society. You cannot use data on political interest and political preferences as we will explore these data in class. You must prepare your report in R Markdown. Submit the pdf file (with all the R syntax visible) through eBart. You should also commit your Rmd file to the course’s Github repo to the studentWork folder. This is not compulsory, but I will mark you down if you do not do this. The Rmd file should have the same name as your student number (for example, “6666666666.Rmd”). Note that I should be able to execute this file so all the file paths must be correct and your syntax must only refer to the data that I have in the data folder. For example, the path to the wave 1 data in your file will be “../data/UKDA-6614-tab/tab/us_w1/a_indresp.tab”. If your Rmd file does not compile I will not have time to fix it and will have to ignore it. I will explain this further in class. Please keep your R syntax clear and provide commentary explaining to me what you do. The deadline for your reports is 29 March at 2pm. I suggest the following steps for your reports. First you need to find a topic that interests you and that has longitudinal data available. Check the User Manual, the questionnaires and data dictionaries for individual waves. Note that the Understanding Society has some modules that are present in each wave and some rotating modules that are only present in one or several waves. Once you have found a variable that interests you make sure that it is present in the data at least at two or more time points. Next you need to read the data into R. Start simple and only read in the data for your outcome variable and maybe sex and age. You will be able to add more variables later as long as you keep your syntax. Clean the data and look at the distributions. Think about the best way to describe and visualise your data. Do you see any interesting patterns and trends? At this stage you should start thinking about the story you want to tell us with your analysis. I do not expect you to do anything fancy statistically. Just providing descriptive statistics and visualisations is fine, as long as I can see that you have thought carefully about which statistics and graphs are best to answer your questions. Every table and chart you have in your report must contribute something to your story. That said, if you want to use some statistical modelling in your report (for example, linear regression) and you do this correctly this will be appreciated and I will give you extra marks for doing this. Once you have a feeling about the general direction of your analysis start adding the details. Maybe you want to explore some more variables; then you need to add them to the data set. For example, for the analysis of political interest I would start with looking at descriptive statistics for political interest for each wave and establish if it was stable or increased/decreased. Then I would think about how I can visualise the results. Then I may start adding details. Was the trend the same for men and women? Different age groups? Different parts of the country? Then if I want to do something fancy I would remember that in 2010 the UK had a general election. Can we get the date of the interview from the data and explore how political interest changed monthly in 2010? And then if I really want to do something very fancy I would read about applyng models with fixed effects to longitudinal data, talk to Alexey in his office hours and explore if change in people’s income over time is associated with the change in political interest. (The latter part is optional.) Write up the results. Start with a brief introduction. For political interest that would be approximately the following: Why are we interested in political interest? What happened in British politics between 2008 and 2016 that could affect the level of political interest? Maybe you can find and cite two or three papers that have already explored this topic. Then present your research questions. What are you aiming to achieve with your report? What questions will you answer? Briefly describe the data (variables you are going to use, what waves they are coming from, etc.). Present your statistical results. The structure of this part will depend on your results. This should not be just a collection of tables and graphs. Explain what you see in all those tables and graphs and why you have included them. Discussion. This is a very important part. You need to discuss here how the statistical results you have got contribute to our understanding of your topic (for example, political interest in Britain). Explain in substantive terms your results and discuss them. Why has political interest increased (or decresed, or ramained stable)? What factors contributed to this? The length of the report is 3,500 words, but I am not going to count your words and writing slightly more or slightly less is fine. Do not submit 100 pages. In the same way, if your report is obviously too short this is going to affect your mark. "],
["joining.html", "4 Joining data from the Understanding Society 4.1 Joining waves 1 and 2 4.2 Joining waves 1 to 7", " 4 Joining data from the Understanding Society At home you read ch.13 on Relational Data from R for Data Science – http://r4ds.had.co.nz/relational-data.html. Let us see how we can apply this to the Understanding Society data. 4.1 Joining waves 1 and 2 I will start with joining data from waves 1 and 2 and then expand the algorithm to all the seven waves. First we need to read the data into R. I am using the fundtion read_tsv() from the readr package here since the data are tab separated. # First I attach the packages I will use later. You need to install these packages first. library(tidyverse) library(data.table) library(reshape2) UndSoc1 &lt;- read_tsv(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;) ## Parsed with column specification: ## cols( ## .default = col_integer(), ## a_jbhrs = col_double(), ## a_extrate = col_double(), ## a_basrate = col_double(), ## a_ovtrate = col_double(), ## a_sf12pcs_dv = col_double(), ## a_sf12mcs_dv = col_double(), ## a_bmi_dv = col_double(), ## a_payg_dv = col_double(), ## a_payn_dv = col_double(), ## a_payu_dv = col_double(), ## a_paygu_dv = col_double(), ## a_paynu_dv = col_double(), ## a_seearngrs_dv = col_double(), ## a_seearnnet_dv = col_double(), ## a_j2pay_dv = col_double(), ## a_fiyrinvinc_dv = col_double(), ## a_fibenothr_dv = col_double(), ## a_fibenothr_if = col_double(), ## a_fimnlabgrs_dv = col_double(), ## a_fimnlabgrs_if = col_double() ## # ... with 16 more columns ## ) ## See spec(...) for full column specifications. ## Warning in rbind(names(probs), probs_f): number of columns of result is not ## a multiple of vector length (arg 1) ## Warning: 13 parsing failures. ## row # A tibble: 5 x 5 col row col expected actual expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1197 a_lenindintv an integer .550000011920929 file 2 1199 a_lenindintv an integer .200000002980232 row 3 1200 a_lenindintv an integer .400000005960464 col 4 4665 a_lenindintv an integer .5 expected 5 5652 a_lenindintv an integer .449999988079071 actual # ... with 1 more variables: file &lt;chr&gt; ## ... ................. ... ................................................ ........ ................................................ ...... ................................................ .... ................................................ ... ................................................ ... ................................................ ........ ................................................ ...... ....................................... ## See problems(...) for more details. UndSoc2 &lt;- read_tsv(&quot;data/UKDA-6614-tab/tab/us_w2/b_indresp.tab&quot;) ## Parsed with column specification: ## cols( ## .default = col_integer(), ## b_jbhrs = col_double(), ## b_extrate = col_double(), ## b_basrate = col_double(), ## b_ovtrate = col_double(), ## b_penmpy = col_double(), ## b_scnalcpint = col_double(), ## b_scnalcshot = col_double(), ## b_scnalcwine = col_double(), ## b_sf12pcs_dv = col_double(), ## b_sf12mcs_dv = col_double(), ## b_payg_dv = col_double(), ## b_payn_dv = col_double(), ## b_payu_dv = col_double(), ## b_paygu_dv = col_double(), ## b_paynu_dv = col_double(), ## b_seearngrs_dv = col_double(), ## b_seearnnet_dv = col_double(), ## b_j2pay_dv = col_double(), ## b_fiyrinvinc_dv = col_double(), ## b_fibenothr_dv = col_double() ## # ... with 25 more columns ## ) ## See spec(...) for full column specifications. ## Warning in rbind(names(probs), probs_f): number of columns of result is not ## a multiple of vector length (arg 1) ## Warning: 43931 parsing failures. ## row # A tibble: 5 x 5 col row col expected actual expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1575 b_indin91_lw no trailing characters .15808284282684 file 2 1575 b_indin01_lw no trailing characters .09862232208252 row 3 1575 b_indpxbh_xw no trailing characters .09886026382446 col 4 1575 b_indinbh_xw no trailing characters .05166864395142 expected 5 1575 b_indscbh_xw no trailing characters .14312696456909 actual # ... with 1 more variables: file &lt;chr&gt; ## ... ................. ... ........................................................... ........ ........................................................... ...... ........................................................... .... ........................................................... ... ........................................................... ... ........................................................... ........ ........................................................... ...... ....................................... ## See problems(...) for more details. These are very large files that take a lot of space in the memory. format(object.size(UndSoc1), units = &quot;auto&quot;) ## [1] &quot;273 Mb&quot; format(object.size(UndSoc2), units = &quot;auto&quot;) ## [1] &quot;350.6 Mb&quot; Before joining these two data frames I may want to select only the variables I need. These are: pidp: this is the unique cross-wave individual number (in both waves), a_sex: sex from wave 1, a_dvage: age from wave 1, a_vote6: level of interest in politics from wave 1, b_sex: sex from wave 2, b_dvage: age from wave 2, b_vote6: level of interest in politics from wave 2. Note that for now I keep it intentionally simple. First I will edit both data sets to keep only the variables I need. UndSoc1ed &lt;- UndSoc1 %&gt;% select(pidp, a_sex, a_dvage, a_vote6) UndSoc2ed &lt;- UndSoc2 %&gt;% select(pidp, b_sex, b_dvage, b_vote6) Note that these are much smaller objects. format(object.size(UndSoc1ed), units = &quot;auto&quot;) ## [1] &quot;1.3 Mb&quot; format(object.size(UndSoc2ed), units = &quot;auto&quot;) ## [1] &quot;5.5 Mb&quot; I will remove the larger data sets from the memory to free it up. rm(UndSoc1, UndSoc2) Let us explore the data. head(UndSoc1ed) ## # A tibble: 6 x 4 ## pidp a_sex a_dvage a_vote6 ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68001367 1 39 3 ## 2 68004087 1 59 2 ## 3 68006127 2 39 4 ## 4 68006135 2 17 4 ## 5 68006807 2 72 4 ## 6 68007487 2 57 1 head(UndSoc2ed) ## # A tibble: 6 x 4 ## pidp b_sex b_dvage b_vote6 ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68004087 1 60 2 ## 2 68006127 2 40 4 ## 3 68006807 2 73 4 ## 4 68007487 2 58 2 ## 5 68008167 2 39 4 ## 6 68008171 1 52 -7 Now we can join the data sets. As you know already, there can be several types of joins. Inner join will keep the observations that match in both data frames. inner &lt;- UndSoc1ed %&gt;% inner_join(UndSoc2ed, by = &quot;pidp&quot;) Note that I use the variable pidp as the key for joining. The same result can be achieved with the function merge from base R. inner2 &lt;- UndSoc1ed %&gt;% merge(UndSoc2ed, by = &quot;pidp&quot;) identical(as.data.frame(inner), inner2) ## [1] TRUE These two data frames are identical. Note the use of as.data.frame(). inner is a tibble and unless converted into a simple data frame it is not identical to inner2 because of the differences in object type. Inner join will only retain individuals that are present in both waves. This is why we only have 38388 observations in the joined data compared to 50994 in wave 1. But do we want this? Imagine that the person is present in wave 1, does not participate in wave 2, but then re-appears in wave 3. We probably want to include such individuals as well. Left join will keep all individuals in wave 1 and only those in wave 2 that can be matched to them. left &lt;- UndSoc1ed %&gt;% left_join(UndSoc2ed, by = &quot;pidp&quot;) # or, identically, # left &lt;- UndSoc1ed %&gt;% # merge(UndSoc2ed, by = &quot;pidp&quot;, all.x = TRUE) You can check that the number of individuals in wave 1 and the joined data frame is the same. Right join will keep all individuals from wave 2 and only those from wave 1 that can be matched to them. right &lt;- UndSoc1ed %&gt;% right_join(UndSoc2ed, by = &quot;pidp&quot;) # or, identically, # right &lt;- UndSoc1ed %&gt;% # merge(UndSoc2ed, by = &quot;pidp&quot;, all.y = TRUE) Usually I would want all the individuals from both waves to remain in the data set, no matter if they can be matched to other waves. If I need to exclude them from the analysis I prefer to do this manually. This can be achieved with full join. full &lt;- UndSoc1ed %&gt;% full_join(UndSoc2ed, by = &quot;pidp&quot;) # or, identically, # full &lt;- UndSoc1ed %&gt;% # merge(UndSoc2ed, by = &quot;pidp&quot;, all = TRUE) Note that full has 67203 observations compared to 50994 in wave 1 and 54597 in wave 2. This is because it includes a) all individuals that took part in both waves 1 and 2, b) those who took part in wave 1, but not in wave 2, c) those who missed wave 1 but joined the study in wave 2. Let us explore the joined data set. head(full) ## # A tibble: 6 x 7 ## pidp a_sex a_dvage a_vote6 b_sex b_dvage b_vote6 ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68001367 1 39 3 NA NA NA ## 2 68004087 1 59 2 1 60 2 ## 3 68006127 2 39 4 2 40 4 ## 4 68006135 2 17 4 NA NA NA ## 5 68006807 2 72 4 2 73 4 ## 6 68007487 2 57 1 2 58 2 We have missing values for wave 1 variable for those people who joined in wave 2. 4.2 Joining waves 1 to 7 Now let us join data from all seven waves. The challenge here is that we do not want to do every operation seven times so we may want to use some iterative tools that we learned last week. Note that the variables across the waves are named consistently, and the difference between the variables from different waves is the prefix that changes from “a” in wave 1 to “g” in wave 7. We may want to write a loop that reads a file for a particular wave into R, selects only the variables we need, joins the data, removes the original file from the memory and proceeds to the next wave. First let us clean the space and remove all the existing objects from the memory. rm(list = ls()) Now we will create a character vector with the full paths to the individual indresp files from all the waves. files &lt;- dir(&quot;data/UKDA-6614-tab/tab&quot;, pattern=&quot;indresp&quot;, recursive = TRUE, full.names=TRUE) files ## [1] &quot;data/UKDA-6614-tab/tab/bhps_w1/ba_indresp.tab&quot; ## [2] &quot;data/UKDA-6614-tab/tab/bhps_w10/bj_indresp.tab&quot; ## [3] &quot;data/UKDA-6614-tab/tab/bhps_w11/bk_indresp.tab&quot; ## [4] &quot;data/UKDA-6614-tab/tab/bhps_w12/bl_indresp.tab&quot; ## [5] &quot;data/UKDA-6614-tab/tab/bhps_w13/bm_indresp.tab&quot; ## [6] &quot;data/UKDA-6614-tab/tab/bhps_w14/bn_indresp.tab&quot; ## [7] &quot;data/UKDA-6614-tab/tab/bhps_w15/bo_indresp.tab&quot; ## [8] &quot;data/UKDA-6614-tab/tab/bhps_w16/bp_indresp.tab&quot; ## [9] &quot;data/UKDA-6614-tab/tab/bhps_w17/bq_indresp.tab&quot; ## [10] &quot;data/UKDA-6614-tab/tab/bhps_w18/br_indresp.tab&quot; ## [11] &quot;data/UKDA-6614-tab/tab/bhps_w2/bb_indresp.tab&quot; ## [12] &quot;data/UKDA-6614-tab/tab/bhps_w3/bc_indresp.tab&quot; ## [13] &quot;data/UKDA-6614-tab/tab/bhps_w4/bd_indresp.tab&quot; ## [14] &quot;data/UKDA-6614-tab/tab/bhps_w5/be_indresp.tab&quot; ## [15] &quot;data/UKDA-6614-tab/tab/bhps_w6/bf_indresp.tab&quot; ## [16] &quot;data/UKDA-6614-tab/tab/bhps_w7/bg_indresp.tab&quot; ## [17] &quot;data/UKDA-6614-tab/tab/bhps_w8/bh_indresp.tab&quot; ## [18] &quot;data/UKDA-6614-tab/tab/bhps_w9/bi_indresp.tab&quot; ## [19] &quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot; ## [20] &quot;data/UKDA-6614-tab/tab/us_w2/b_indresp.tab&quot; ## [21] &quot;data/UKDA-6614-tab/tab/us_w3/c_indresp.tab&quot; ## [22] &quot;data/UKDA-6614-tab/tab/us_w4/d_indresp.tab&quot; ## [23] &quot;data/UKDA-6614-tab/tab/us_w5/e_indresp.tab&quot; ## [24] &quot;data/UKDA-6614-tab/tab/us_w6/f_indresp.tab&quot; ## [25] &quot;data/UKDA-6614-tab/tab/us_w7/g_indresp.tab&quot; This includes files from the BHPS that we don’t need so let us drop them. We can use the function str_detect() (part of the stringr package) to identify files from the Understanding Society only and then keep only their names in the vector files. str_detect(files, &quot;us&quot;) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [12] FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE ## [23] TRUE TRUE TRUE files &lt;- files[str_detect(files, &quot;us&quot;)] files ## [1] &quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot; ## [2] &quot;data/UKDA-6614-tab/tab/us_w2/b_indresp.tab&quot; ## [3] &quot;data/UKDA-6614-tab/tab/us_w3/c_indresp.tab&quot; ## [4] &quot;data/UKDA-6614-tab/tab/us_w4/d_indresp.tab&quot; ## [5] &quot;data/UKDA-6614-tab/tab/us_w5/e_indresp.tab&quot; ## [6] &quot;data/UKDA-6614-tab/tab/us_w6/f_indresp.tab&quot; ## [7] &quot;data/UKDA-6614-tab/tab/us_w7/g_indresp.tab&quot; Now let us write the loop. # These are the variables we want to select from each wave without prefixes # (exclusing pidp). vars &lt;- c(&quot;sex&quot;, &quot;dvage&quot;, &quot;vote6&quot;) # We will loop over numbers from 1 to 7 for (i in 1:7) { # Create a vector of the variables to select. I need to add the prefix. # Note the use of the function letters() varsToSelect &lt;- paste(letters[i], vars, sep = &quot;_&quot;) # Add pidp (no prefix for pidp) varsToSelect &lt;- c(&quot;pidp&quot;, varsToSelect) # Now read the data. I only need to read the select variables. # I will use the fread() function from the data.table package # (it&#39;s faster and it&#39;s easier to select only some variables) data &lt;- fread(files[i], select = varsToSelect) # Now, if this is the first iteration of the loop we simply want to initialise # the data frame with these data. # If this is not the first iteration of the loop # we need to use full_join. # To achieve this result we will use the conditional operator if... else if (i == 1) { all7 &lt;- data } else { all7 &lt;- full_join(all7, data, by = &quot;pidp&quot;) } # Now we can remove the full data frame rm(data) } ## Read 60.3% of 49739 rows Read 49739 rows and 4 (of 3024) columns from 0.402 GB file in 00:00:04 ## Read 84.8% of 47157 rows Read 47157 rows and 4 (of 2086) columns from 0.262 GB file in 00:00:03 ## Read 66.8% of 44903 rows Read 44903 rows and 4 (of 2583) columns from 0.310 GB file in 00:00:03 ## Read 88.3% of 45290 rows Read 45290 rows and 4 (of 2060) columns from 0.263 GB file in 00:00:03 ## Read 71.1% of 42217 rows Read 42217 rows and 4 (of 2799) columns from 0.321 GB file in 00:00:03 # Check the result colnames(all7) ## [1] &quot;pidp&quot; &quot;a_sex&quot; &quot;a_dvage&quot; &quot;a_vote6&quot; &quot;b_sex&quot; &quot;b_dvage&quot; &quot;b_vote6&quot; ## [8] &quot;c_sex&quot; &quot;c_dvage&quot; &quot;c_vote6&quot; &quot;d_sex&quot; &quot;d_dvage&quot; &quot;d_vote6&quot; &quot;e_sex&quot; ## [15] &quot;e_dvage&quot; &quot;e_vote6&quot; &quot;f_sex&quot; &quot;f_dvage&quot; &quot;f_vote6&quot; &quot;g_sex&quot; &quot;g_dvage&quot; ## [22] &quot;g_vote6&quot; head(all7) ## pidp a_sex a_dvage a_vote6 b_sex b_dvage b_vote6 c_sex c_dvage ## 1 68001367 1 39 3 NA NA NA NA NA ## 2 68004087 1 59 2 1 60 2 1 61 ## 3 68006127 2 39 4 2 40 4 2 41 ## 4 68006135 2 17 4 NA NA NA 2 19 ## 5 68006807 2 72 4 2 73 4 2 74 ## 6 68007487 2 57 1 2 58 2 2 59 ## c_vote6 d_sex d_dvage d_vote6 e_sex e_dvage e_vote6 f_sex f_dvage ## 1 NA NA NA NA NA NA NA NA NA ## 2 2 1 62 1 1 63 2 1 64 ## 3 4 2 43 4 2 43 4 2 44 ## 4 4 2 21 2 2 21 4 NA NA ## 5 4 2 75 4 2 76 4 2 77 ## 6 4 2 60 1 NA NA NA NA NA ## f_vote6 g_sex g_dvage g_vote6 ## 1 NA NA NA NA ## 2 2 1 65 2 ## 3 4 2 45 4 ## 4 NA 2 23 -7 ## 5 4 2 78 3 ## 6 NA NA NA NA Now I will save this joined data frame for the future use. I will write it into the myData folder. Make sure that this folder is NOT tracked on Github as a) the data file is too large for tracking, b) we cannot put data in public access. To keep the folder untracked, just add the following line to your .gitignore file: myData/ # You need to create the myData folder first write_tsv(all7, &quot;myData/all7.tab&quot;) "],
["tidy-data.html", "5 Tidy data 5.1 Long and wide formats 5.2 Cleaning the data 5.3 Homework", " 5 Tidy data In the previous part of the course (joiningData.Rmd) we learned how to join together data from seven waves of the Understanding Society. Let us open this data set. UndSoc &lt;- read_tsv(&quot;myData/all7.tab&quot;) ## Parsed with column specification: ## cols( ## .default = col_integer() ## ) ## See spec(...) for full column specifications. head(UndSoc) ## # A tibble: 6 x 22 ## pidp a_sex a_dvage a_vote6 b_sex b_dvage b_vote6 c_sex c_dvage ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68001367 1 39 3 NA NA NA NA NA ## 2 68004087 1 59 2 1 60 2 1 61 ## 3 68006127 2 39 4 2 40 4 2 41 ## 4 68006135 2 17 4 NA NA NA 2 19 ## 5 68006807 2 72 4 2 73 4 2 74 ## 6 68007487 2 57 1 2 58 2 2 59 ## # ... with 13 more variables: c_vote6 &lt;int&gt;, d_sex &lt;int&gt;, d_dvage &lt;int&gt;, ## # d_vote6 &lt;int&gt;, e_sex &lt;int&gt;, e_dvage &lt;int&gt;, e_vote6 &lt;int&gt;, f_sex &lt;int&gt;, ## # f_dvage &lt;int&gt;, f_vote6 &lt;int&gt;, g_sex &lt;int&gt;, g_dvage &lt;int&gt;, ## # g_vote6 &lt;int&gt; Now we will work on how these data can be represented and prepared for the analysis. Please read ch.12 on Tidy Data from the R for Data Science Book – http://r4ds.had.co.nz/tidy-data.html. 5.1 Long and wide formats Let us keep only a few observations and columns in the data and more closely look at its structure. UndSocExample &lt;- UndSoc %&gt;% filter(pidp == 68001367 | pidp == 68004087) %&gt;% select(pidp, a_sex: b_vote6) UndSocExample ## # A tibble: 2 x 7 ## pidp a_sex a_dvage a_vote6 b_sex b_dvage b_vote6 ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68001367 1 39 3 NA NA NA ## 2 68004087 1 59 2 1 60 2 These are the data for two individuals only in waves 1 and 2. The data are represented in the wide format. This means that we have one row for each individual, and data from different waves are recorded in several columns. For example, the data on sex from wave 1 is in column a_sex and the data on sex from wave is in b_sex. You will find this representation of the data common in longitudinal data sets. It may be convenient for certain purposes, but it is generally recommended to keep the data in the long format (that corresponds to the tidy data principles as described in the R for Data Science book). To move from the wide to the long format we can use the function melt and cast functions from the reshape2 package. require(reshape2) # First we &quot;melt&quot; the data frame. UndSocExampleMolten &lt;- UndSocExample %&gt;% melt(id = &quot;pidp&quot;) UndSocExampleMolten ## pidp variable value ## 1 68001367 a_sex 1 ## 2 68004087 a_sex 1 ## 3 68001367 a_dvage 39 ## 4 68004087 a_dvage 59 ## 5 68001367 a_vote6 3 ## 6 68004087 a_vote6 2 ## 7 68001367 b_sex NA ## 8 68004087 b_sex 1 ## 9 68001367 b_dvage NA ## 10 68004087 b_dvage 60 ## 11 68001367 b_vote6 NA ## 12 68004087 b_vote6 2 # Next I want to split the column variable into a column indicating wave and a column indicating variable name. # I will use the function separate() from tidyr. UndSocExampleSep &lt;- UndSocExampleMolten %&gt;% separate(variable, into = c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;) UndSocExampleSep ## pidp wave variable value ## 1 68001367 a sex 1 ## 2 68004087 a sex 1 ## 3 68001367 a dvage 39 ## 4 68004087 a dvage 59 ## 5 68001367 a vote6 3 ## 6 68004087 a vote6 2 ## 7 68001367 b sex NA ## 8 68004087 b sex 1 ## 9 68001367 b dvage NA ## 10 68004087 b dvage 60 ## 11 68001367 b vote6 NA ## 12 68004087 b vote6 2 # Next we &quot;cast&quot; the molten data frame into the format we want. UndSocExampleLong &lt;- UndSocExampleSep %&gt;% dcast(pidp + wave ~ variable) UndSocExampleLong ## pidp wave dvage sex vote6 ## 1 68001367 a 39 1 3 ## 2 68001367 b NA NA NA ## 3 68004087 a 59 1 2 ## 4 68004087 b 60 1 2 Now the data are in the “long format”. This means that we have as many rows for each individual as the number of waves, a variable indicating wave, and all other variables are in columns. In most cases with longitudinal data, the long format is easier to work with. What if we want to convert the data back to the wide format? # First melt UndSocExampleMolten2 &lt;- UndSocExampleLong %&gt;% melt(id = c(&quot;pidp&quot;, &quot;wave&quot;)) UndSocExampleMolten2 ## pidp wave variable value ## 1 68001367 a dvage 39 ## 2 68001367 b dvage NA ## 3 68004087 a dvage 59 ## 4 68004087 b dvage 60 ## 5 68001367 a sex 1 ## 6 68001367 b sex NA ## 7 68004087 a sex 1 ## 8 68004087 b sex 1 ## 9 68001367 a vote6 3 ## 10 68001367 b vote6 NA ## 11 68004087 a vote6 2 ## 12 68004087 b vote6 2 # Unite the columns UndSocExampleUnited &lt;- UndSocExampleMolten2 %&gt;% unite(&quot;variable&quot;, c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;) UndSocExampleUnited ## pidp variable value ## 1 68001367 a_dvage 39 ## 2 68001367 b_dvage NA ## 3 68004087 a_dvage 59 ## 4 68004087 b_dvage 60 ## 5 68001367 a_sex 1 ## 6 68001367 b_sex NA ## 7 68004087 a_sex 1 ## 8 68004087 b_sex 1 ## 9 68001367 a_vote6 3 ## 10 68001367 b_vote6 NA ## 11 68004087 a_vote6 2 ## 12 68004087 b_vote6 2 # And now cast UndSocExampleWide &lt;- UndSocExampleUnited %&gt;% dcast(pidp ~ variable) UndSocExampleWide ## pidp a_dvage a_sex a_vote6 b_dvage b_sex b_vote6 ## 1 68001367 39 1 3 NA NA NA ## 2 68004087 59 1 2 60 1 2 We can also restructure the data using the gather and spread functions from the tidyr package (part of tidyverse). gather is roughy equivalent to melt and spread is roughy equivalent to dcast. Moving from wide to long: UndSocExample ## # A tibble: 2 x 7 ## pidp a_sex a_dvage a_vote6 b_sex b_dvage b_vote6 ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68001367 1 39 3 NA NA NA ## 2 68004087 1 59 2 1 60 2 # This &quot;melts&quot; the data frame. UndSocExample %&gt;% gather(a_sex:b_vote6, key = &quot;variable&quot;, value = &quot;value&quot;) ## # A tibble: 12 x 3 ## pidp variable value ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 68001367 a_sex 1 ## 2 68004087 a_sex 1 ## 3 68001367 a_dvage 39 ## 4 68004087 a_dvage 59 ## 5 68001367 a_vote6 3 ## 6 68004087 a_vote6 2 ## 7 68001367 b_sex NA ## 8 68004087 b_sex 1 ## 9 68001367 b_dvage NA ## 10 68004087 b_dvage 60 ## 11 68001367 b_vote6 NA ## 12 68004087 b_vote6 2 # Next we want to split the &quot;variable&quot; column and &quot;cast&quot; in the long format UndSocExample %&gt;% gather(a_sex:b_vote6, key = &quot;variable&quot;, value = &quot;value&quot;) %&gt;% separate(variable, into = c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;) %&gt;% spread(key = variable, value = value) ## # A tibble: 4 x 5 ## pidp wave dvage sex vote6 ## * &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68001367 a 39 1 3 ## 2 68001367 b NA NA NA ## 3 68004087 a 59 1 2 ## 4 68004087 b 60 1 2 If we want to move from long to wide: UndSocExampleLong ## pidp wave dvage sex vote6 ## 1 68001367 a 39 1 3 ## 2 68001367 b NA NA NA ## 3 68004087 a 59 1 2 ## 4 68004087 b 60 1 2 UndSocExampleLong %&gt;% gather(dvage:vote6, key = &quot;variable&quot;, value = &quot;value&quot;) %&gt;% unite(&quot;variable&quot;, c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;) %&gt;% spread(key = variable, value = value) ## pidp a_dvage a_sex a_vote6 b_dvage b_sex b_vote6 ## 1 68001367 39 1 3 NA NA NA ## 2 68004087 59 1 2 60 1 2 Exercise. Reshape the full UndSoc data frame from wide to long format. Call the object where you will store the result UndSocLong. Solution: UndSocLong &lt;- UndSoc %&gt;% gather(a_sex:g_vote6, key = &quot;variable&quot;, value = &quot;value&quot;) %&gt;% separate(variable, into = c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;) %&gt;% spread(key = variable, value = value) UndSocLong ## # A tibble: 584,703 x 5 ## pidp wave dvage sex vote6 ## * &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 22445 a NA NA NA ## 2 22445 b NA NA NA ## 3 22445 c NA NA NA ## 4 22445 d 27 2 2 ## 5 22445 e 28 2 2 ## 6 22445 f 29 2 2 ## 7 22445 g 30 2 1 ## 8 29925 a NA NA NA ## 9 29925 b NA NA NA ## 10 29925 c NA NA NA ## # ... with 584,693 more rows 5.2 Cleaning the data Before we begin the analysis we want to make sure that the data have been cleaned and all the missing values have been correctly identified. It usually makes sense to separate the cleaning and analysis stages into separate scripts. Let us explore the data set we have. Note that if we had not converted the data into the long format we would have to tabulate and clean each variable seven times. summary(UndSocLong) ## pidp wave dvage sex ## Min. :2.244e+04 Length:584703 Min. : -9.00 Min. :-9.00 ## 1st Qu.:4.086e+08 Class :character 1st Qu.: 32.00 1st Qu.: 1.00 ## Median :7.493e+08 Mode :character Median : 46.00 Median : 2.00 ## Mean :7.973e+08 Mean : 47.09 Mean : 1.54 ## 3rd Qu.:1.224e+09 3rd Qu.: 61.00 3rd Qu.: 2.00 ## Max. :1.653e+09 Max. :104.00 Max. : 2.00 ## NA&#39;s :249806 NA&#39;s :249806 ## vote6 ## Min. :-10.00 ## 1st Qu.: 2.00 ## Median : 3.00 ## Mean : 1.82 ## 3rd Qu.: 4.00 ## Max. : 4.00 ## NA&#39;s :249806 table(UndSocLong$wave) ## ## a b c d e f g ## 83529 83529 83529 83529 83529 83529 83529 table(UndSocLong$dvage) ## ## -9 -2 -1 16 17 18 19 20 21 22 23 24 25 26 27 ## 19 6 34 5735 5769 5536 5350 5188 5000 4779 4668 4537 4555 4556 4610 ## 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 ## 4742 4836 5129 5181 5286 5387 5380 5512 5591 5519 5765 5896 6155 6274 6422 ## 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 ## 6291 6450 6489 6316 6263 6187 6119 6013 5901 5727 5701 5483 5406 5193 5042 ## 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 ## 5052 4856 4782 4962 4995 5013 4999 4846 4814 4666 4435 4210 3914 3707 3504 ## 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 ## 3316 3130 2977 2749 2618 2452 2241 2106 1886 1749 1599 1390 1211 988 860 ## 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 ## 683 547 453 344 243 172 131 92 80 41 36 25 15 6 2 ## 103 104 ## 1 1 table(UndSocLong$sex) ## ## -9 -1 1 2 ## 2 1 154045 180849 table(UndSocLong$vote6) ## ## -10 -9 -7 -2 -1 1 2 3 4 ## 4656 366 24752 431 358 30981 102212 86790 84351 Note the negative values for dvage, sex and vote6. These are missing values that need to be coded as missing. UndSocLong &lt;- UndSocLong %&gt;% mutate(dvage = ifelse(dvage &gt; 0, dvage, NA)) %&gt;% mutate(sex = ifelse(sex &gt; 0, sex, NA)) %&gt;% mutate(vote6 = ifelse(vote6 &gt; 0, vote6, NA)) table(UndSocLong$dvage) ## ## 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ## 5735 5769 5536 5350 5188 5000 4779 4668 4537 4555 4556 4610 4742 4836 5129 ## 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 ## 5181 5286 5387 5380 5512 5591 5519 5765 5896 6155 6274 6422 6291 6450 6489 ## 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 ## 6316 6263 6187 6119 6013 5901 5727 5701 5483 5406 5193 5042 5052 4856 4782 ## 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 ## 4962 4995 5013 4999 4846 4814 4666 4435 4210 3914 3707 3504 3316 3130 2977 ## 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 ## 2749 2618 2452 2241 2106 1886 1749 1599 1390 1211 988 860 683 547 453 ## 91 92 93 94 95 96 97 98 99 100 101 102 103 104 ## 344 243 172 131 92 80 41 36 25 15 6 2 1 1 table(UndSocLong$sex) ## ## 1 2 ## 154045 180849 table(UndSocLong$vote6) ## ## 1 2 3 4 ## 30981 102212 86790 84351 We may also want to code sex as “male” and “female” and assign meaningful labels to vote6 converting these variables into factors. UndSocLongClean &lt;- UndSocLong %&gt;% mutate(sex = recode(sex, &quot;1&quot; = &quot;male&quot;, &quot;2&quot; = &quot;female&quot;)) %&gt;% mutate(vote6 = recode(vote6, &quot;1&quot; = &quot;very&quot;, &quot;2&quot; = &quot;fairly&quot;, &quot;3&quot; = &quot;not very&quot;, &quot;4&quot; = &quot;not al all&quot;)) %&gt;% mutate(sex = factor(sex)) %&gt;% mutate(vote6 = factor(vote6)) UndSocLongClean ## # A tibble: 584,703 x 5 ## pidp wave dvage sex vote6 ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;fctr&gt; &lt;fctr&gt; ## 1 22445 a NA &lt;NA&gt; &lt;NA&gt; ## 2 22445 b NA &lt;NA&gt; &lt;NA&gt; ## 3 22445 c NA &lt;NA&gt; &lt;NA&gt; ## 4 22445 d 27 female fairly ## 5 22445 e 28 female fairly ## 6 22445 f 29 female fairly ## 7 22445 g 30 female very ## 8 29925 a NA &lt;NA&gt; &lt;NA&gt; ## 9 29925 b NA &lt;NA&gt; &lt;NA&gt; ## 10 29925 c NA &lt;NA&gt; &lt;NA&gt; ## # ... with 584,693 more rows write_tsv(UndSocLongClean, &quot;myData/all7clean.tab&quot;) 5.3 Homework To prepare for the class on 19 February please read ch. 3 (Data visualisation) from the R for Data Science book and do all the exercises – http://r4ds.had.co.nz/data-visualisation.html Please also read ch.12 on tidy data and do all the exercises – http://r4ds.had.co.nz/tidy-data.html "],
["datavis.html", "6 Data visualisation 6.1 Reading in the data 6.2 Visualising one quantitative variable 6.3 Visualising one categorical variable 6.4 Visualising two quantitative variables 6.5 Visualising one categorical and one quantitative variable 6.6 Visualising two categorical variables 6.7 Showing the relationships by group", " 6 Data visualisation Pre-requisite for this class: ch.3 (“Data visualisation”) from R for Data Science - http://r4ds.had.co.nz/data-visualisation.html At home you learned about the basic principles of data visualisation in R with the ggplot2 package. Let us see how we can apply this to the Understanding Society data set. Personally I can never remember all the details of the ggplot2 syntax. I often use the ready-made “recipes” from the R Graphics Cookbook by W.Chang – https://www.amazon.co.uk/R-Graphics-Cookbook-Winston-Chang/dp/1449316956/. The 2nd edition is coming out later this year – https://www.amazon.co.uk/Graphics-Cookbook-2e-Winston-Chang/dp/1491978600 . You may also find Winston Chang’s website useful (and not only for graphics) - http://www.cookbook-r.com . 6.1 Reading in the data First let us read in the data we used in week 2 when we learned about dplyr (a short version of the wave 1 data) and recreate the measures for weight, height and BMI. library(tidyverse) library(data.table) W1 &lt;- fread(&quot;exData/W1.csv&quot;) W1 &lt;- W1 %&gt;% mutate(heightcm = ifelse(a_hlht == 1 &amp; a_hlhtf &gt; 0, a_hlhtf*30.48 + a_hlhti*2.54, ifelse(a_hlht == 2 &amp; a_hlhtc &gt; 0, a_hlhtc, NA))) %&gt;% mutate(weightkg = ifelse(a_hlwt == 1 &amp; a_hlwts &gt; 0, a_hlwts*6.35 + a_hlwtp*0.45, ifelse(a_hlwt == 2 &amp; a_hlwtk &gt; 0, a_hlwtk, NA))) %&gt;% mutate(bmi = weightkg / (heightcm / 100)^2) head(W1, 3) ## pidp a_sex a_dvage a_ukborn a_racel a_hlht a_hlhtf a_hlhti a_hlhtc ## 1 68001367 1 39 1 1 1 6 0 -8 ## 2 68004087 1 59 5 4 1 5 11 -8 ## 3 68006127 2 39 1 1 1 5 1 -8 ## a_hlwt a_hlwts a_hlwtp a_hlwtk a_vote1 a_vote2 a_vote3 a_vote4 a_vote5 ## 1 1 15 8 -8 2 2 1 -8 3 ## 2 2 -8 -8 70 1 -8 -8 1 3 ## 3 1 14 7 -8 2 2 95 -8 -8 ## a_vote6 heightcm weightkg bmi ## 1 3 182.88 98.85 29.55590 ## 2 2 180.34 70.00 21.52355 ## 3 4 154.94 92.05 38.34394 6.2 Visualising one quantitative variable Exercise. Visualise the distribution of the BMI with ggplot2. Which statistical graphs would be appropriate for this? 6.2.1 Histogram. ggplot(W1, aes(x=bmi)) + geom_histogram(bins = 100) + xlab(&quot;Body mass index&quot;) ## Warning: Removed 6426 rows containing non-finite values (stat_bin). 6.2.2 Density chart. ggplot(W1, aes(x=bmi)) + geom_density() + xlab(&quot;Body mass index&quot;) ## Warning: Removed 6426 rows containing non-finite values (stat_density). 6.3 Visualising one categorical variable Exercise. Visualise the distribution of a_ukborn with ggplot2. Which statistical graphs would be appropriate for this? 6.3.1 Bar plot. table(W1$a_ukborn) ## ## -9 -2 -1 1 2 3 4 5 ## 6 2 8 33480 3567 2154 2033 9744 W1 &lt;- W1 %&gt;% mutate(a_ukborn = ifelse(a_ukborn &gt; 0, a_ukborn, NA)) %&gt;% mutate(cbirth = recode(a_ukborn, &quot;1&quot; = &quot;England&quot;, &quot;2&quot; = &quot;Scotland&quot;, &quot;3&quot; = &quot;Wales&quot;, &quot;4&quot; = &quot;Northern Ireland&quot;, &quot;5&quot; = &quot;Not UK&quot;)) table(W1$cbirth) ## ## England Northern Ireland Not UK Scotland ## 33480 2033 9744 3567 ## Wales ## 2154 W1 %&gt;% filter(!is.na(cbirth)) %&gt;% ggplot(aes(x=cbirth)) + geom_bar() + xlab(&quot;Country of birth&quot;) table(W1$cbirth, useNA = &quot;always&quot;) ## ## England Northern Ireland Not UK Scotland ## 33480 2033 9744 3567 ## Wales &lt;NA&gt; ## 2154 16 6.4 Visualising two quantitative variables Exercise. Visualise the joint distribution of weight (in kg) and height (in cm). In your chart show the regression line and the nonparametric smoothing line. ggplot(W1, aes(x = weightkg, y= heightcm)) + geom_point() + geom_smooth() + stat_smooth(method=lm) ## `geom_smooth()` using method = &#39;gam&#39; ## Warning: Removed 6426 rows containing non-finite values (stat_smooth). ## Warning: Removed 6426 rows containing non-finite values (stat_smooth). ## Warning: Removed 6426 rows containing missing values (geom_point). 6.5 Visualising one categorical and one quantitative variable Exercise. Visualise the distribution of BMI for a) men and women, b) different age groups. 6.6 Visualising two categorical variables Exercise. Use facets to visualise the distribution of a_ukborn by age group. 6.7 Showing the relationships by group Exercise. Use facets to visualise the association between age and BMI by ethnic group. "]
]
